{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEST_COUNTRY_NAME,ORIGIN_COUNTRY_NAME,count\r\n",
      "United States,Romania,15\r\n",
      "United States,Croatia,1\r\n",
      "United States,Ireland,344\r\n",
      "Egypt,United States,15\r\n",
      "United States,India,62\r\n",
      "United States,Singapore,1\r\n",
      "United States,Grenada,62\r\n",
      "Costa Rica,United States,588\r\n",
      "Senegal,United States,40\r\n"
     ]
    }
   ],
   "source": [
    "!head ../../../Spark-The-Definitive-Guide/data/flight-data/csv/2015-summary.csv"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T20:08:01.522677Z",
     "start_time": "2023-06-14T20:08:01.147268Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f2694418",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T20:08:01.529656Z",
     "start_time": "2023-06-14T20:08:01.526838Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import findspark\n",
    "\n",
    "findspark.init(\n",
    "    spark_home=str(Path.cwd() / \"..\" / \"ext\" / \"spark-3.4.0-bin-hadoop3\")\n",
    ")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import desc, max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab15fb7",
   "metadata": {},
   "source": [
    "# Flight data analysis (SQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "375efc32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T20:08:01.577600Z",
     "start_time": "2023-06-14T20:08:01.532336Z"
    }
   },
   "outputs": [],
   "source": [
    "# Spark UI is available at localhost:4040\n",
    "spark = (\n",
    "    SparkSession.builder.master(\"local\")\n",
    "    .appName(\"e1:flights\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4263f777",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T20:08:01.692679Z",
     "start_time": "2023-06-14T20:08:01.607543Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data into data frame\n",
    "flight_data = (\n",
    "    spark.read.option(\"inferSchema\", \"true\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .csv(\n",
    "        \"../../../Spark-The-Definitive-Guide/data/flight-data/csv/2015-summary.csv\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cc9c370d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T20:08:01.697787Z",
     "start_time": "2023-06-14T20:08:01.694555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "caccd091",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T20:08:01.765946Z",
     "start_time": "2023-06-14T20:08:01.698029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|   15|\n",
      "|    United States|            Croatia|    1|\n",
      "|    United States|            Ireland|  344|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight_data.show(3)\n",
    "# flight_data.rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "36a6664e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T20:08:01.772835Z",
     "start_time": "2023-06-14T20:08:01.765536Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data into a table\n",
    "flight_data.createOrReplaceTempView(\"flight_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "sql_way = spark.sql(\n",
    "\"\"\"\n",
    "SELECT DEST_COUNTRY_NAME, count(*)\n",
    "FROM flight_data\n",
    "GROUP BY DEST_COUNTRY_NAME\n",
    "ORDER BY 2 DESC\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# sql_way.explain()\n",
    "# sql_way.show(3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T20:08:01.781390Z",
     "start_time": "2023-06-14T20:08:01.774479Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "afe4f216",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T20:08:01.805308Z",
     "start_time": "2023-06-14T20:08:01.783362Z"
    }
   },
   "outputs": [],
   "source": [
    "data_frame_way = flight_data\\\n",
    "    .groupBy(\"DEST_COUNTRY_NAME\").count()\\\n",
    "    .sort(desc(\"count\"))\n",
    "\n",
    "# data_frame_way.explain()\n",
    "# data_frame_way.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b7ba10",
   "metadata": {},
   "source": [
    "### Establish the maximum number of flights to and from any given location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9f15bbfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T20:08:01.845671Z",
     "start_time": "2023-06-14T20:08:01.805501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|max(count)|\n",
      "+----------+\n",
      "|    370002|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sql syntax\n",
    "spark.sql(\"SELECT max(count) from flight_data\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "55f19b91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T20:08:01.896183Z",
     "start_time": "2023-06-14T20:08:01.846492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|max(count)|\n",
      "+----------+\n",
      "|    370002|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataframe syntax\n",
    "flight_data.select(max(\"count\")).show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4830edf",
   "metadata": {},
   "source": [
    "### Find the top five destination countries in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "20d90d31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T20:08:01.990445Z",
     "start_time": "2023-06-14T20:08:01.897432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|DEST_COUNTRY_NAME|destination_total|\n",
      "+-----------------+-----------------+\n",
      "|    United States|           411352|\n",
      "|           Canada|             8399|\n",
      "|           Mexico|             7140|\n",
      "|   United Kingdom|             2025|\n",
      "|            Japan|             1548|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sql syntax\n",
    "max_sql = spark.sql(\n",
    "\"\"\"\n",
    "SELECT DEST_COUNTRY_NAME, sum(count) as destination_total\n",
    "FROM flight_data\n",
    "GROUP BY DEST_COUNTRY_NAME\n",
    "ORDER BY sum(count) DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "max_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d010ef75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T20:08:02.079856Z",
     "start_time": "2023-06-14T20:08:01.991995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|DEST_COUNTRY_NAME|destination_total|\n",
      "+-----------------+-----------------+\n",
      "|    United States|           411352|\n",
      "|           Canada|             8399|\n",
      "|           Mexico|             7140|\n",
      "|   United Kingdom|             2025|\n",
      "|            Japan|             1548|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dataframe syntax\n",
    "\n",
    "flight_data.groupBy(\"DEST_COUNTRY_NAME\").sum(\"count\").withColumnRenamed(\n",
    "    \"sum(count)\", \"destination_total\"\n",
    ").sort(desc(\"destination_total\")).limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "21041865",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T20:08:02.579898Z",
     "start_time": "2023-06-14T20:08:02.083189Z"
    }
   },
   "outputs": [],
   "source": [
    "# close session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9227ec64",
   "metadata": {},
   "source": [
    "## Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b170546c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T20:08:04.019148Z",
     "start_time": "2023-06-14T20:08:02.585918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------+-------+\n",
      "|User ID|Username|Browser|     OS|\n",
      "+-------+--------+-------+-------+\n",
      "|   1580|   Barry|FireFox|Windows|\n",
      "|   5820|     Sam|MS Edge|  Linux|\n",
      "|   2340|   Harry|Vivaldi|Windows|\n",
      "|   7860|  Albert| Chrome|Windows|\n",
      "|   1123|     May| Safari|  macOS|\n",
      "+-------+--------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "\n",
    "with SparkSession.builder.getOrCreate() as sc:\n",
    "    # Setup the Schema\n",
    "    schema = StructType(\n",
    "        [\n",
    "            StructField(\"User ID\", IntegerType(), True),\n",
    "            StructField(\"Username\", StringType(), True),\n",
    "            StructField(\"Browser\", StringType(), True),\n",
    "            StructField(\"OS\", StringType(), True),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Add Data\n",
    "    data = [\n",
    "        (1580, \"Barry\", \"FireFox\", \"Windows\"),\n",
    "        (5820, \"Sam\", \"MS Edge\", \"Linux\"),\n",
    "        (2340, \"Harry\", \"Vivaldi\", \"Windows\"),\n",
    "        (7860, \"Albert\", \"Chrome\", \"Windows\"),\n",
    "        (1123, \"May\", \"Safari\", \"macOS\"),\n",
    "    ]\n",
    "\n",
    "    user_data_df = sc.createDataFrame(data, schema=schema)\n",
    "    user_data_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
